Agent1.sources = spooldir-source
Agent1.channels = memory-channel
Agent1.sinks = hdfs-sink

###Describe/configure Source
Agent1.sources.spooldir-source.type = spooldir
###Carpeta de origen
Agent1.sources.spooldir-source.spoolDir = /home/acerrato/m3_indiv/def_data/dinamic_data
####Longitud maxima de una linea
Agent1.sources.spooldir-source.deserializer.maxLineLength = 100000
###Codigo para dejarlo en formato JSON y no ensuciar el contenido del archivo
Agent1.sources.spooldir-source.hnadler = org.apache.flume.source.http.JSONHandler


###Describe the sink
Agent1.sinks.hdfs-sink.type = hdfs
###Carpeta de destino en HDFS
Agent1.sinks.hdfs-sink.hdfs.path = /user/acerrato/bicimad_m3/data/streaming
###Dejados en formato Text, fundamental para despues ser tratados con Hive
Agent1.sinks.hdfs-sink.hdfs.writeFormat = Text
###Tama√±o max de archivo 128MB aprox, lo optimo para HDFS
Agent1.sinks.hdfs-sink.hdfs.rollSize = 12800000
###Numero max de filas, en funcion del archivo, optimizado para que se aproxime
###tambien a 128MB, tambien podria haber tomado valor 0
Agent1.sinks.hdfs-sink.hdfs.rollCount = 1
###Nombre del archivo de salida
Agent1.sinks.hdfs-sink.hdfs.filePrefix = usage-
Agent1.sinks.hdfs-sink.hdfs.fileType = DataStream
Agent1.sinks.hdfs-sink.hdfs.round = true
Agent1.sinks.hdfs-sink.hdfs.roundValue = 10
Agent1.sinks.hdfs-sink.hdfs.roundUnit = minute


###Use a channel which buffers events in memory
Agent1.channels.memory-channel.type = memory
Agent1.channels.memory-channel.byteCapacity = 6912212
Agent1.channels.memory-channel.transactionCapacity = 100

###Bind the source and sink to the channel
Agent1.sources.spooldir-source.channels = memory-channel
Agent1.sinks.hdfs-sink.channel = memory-channel
